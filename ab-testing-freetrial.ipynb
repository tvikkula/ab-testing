{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define functions:\n",
    "from __future__ import division\n",
    "from math import sqrt\n",
    "\n",
    "# Confidence interval function:\n",
    "def ci(crit_value, se, statistic):\n",
    "    ci_val = crit_value * se\n",
    "    return ci_val, statistic - ci_val, statistic + ci_val\n",
    "\n",
    "# SE for binomial distribution:\n",
    "def se_binom(p, N):\n",
    "    # Return SE for a binomial distribution\n",
    "    return sqrt((p * (1 - p)) * pooled_N(N))\n",
    "\n",
    "# Define N for se_binom, needs to account pooling:\n",
    "def pooled_N(N):\n",
    "    if isinstance(N, list):\n",
    "        return sum([1/int(val) for val in N])\n",
    "    else:\n",
    "        return 1/N\n",
    "\n",
    "# Function to define days needed to run an experiment:\n",
    "def days_needed_to_run(needed_size, daily_visits, traffic_ratio):\n",
    "    return needed_size / daily_visits / traffic_ratio\n",
    "\n",
    "# a factory function to handle '' when creating ints\n",
    "def make_int(num):\n",
    "    return int(num) if num else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First define the experiment metrics:\n",
    "\n",
    "Evaluation:\n",
    "1. Gross conversion: enroll/start_free_trial —> Should reduce, reject NULL, oneway negative\n",
    "2. Retention: payment/enroll —> Should increase, reject NULL, oneway positive\n",
    "3. Net conv: payment/start_free_trial —> Should not change. keep NULL, twoway\n",
    "\n",
    "Invariant (these should not change between experiment and control):\n",
    "1. Pageviews\n",
    "2. Clicks (start a free trial)\n",
    "3. Clickthrough: clicks/pageviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline values\n",
    "\n",
    "The baseline values for these are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08\n",
      "0.0165\n",
      "400.0\n",
      "82.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# probabilities:\n",
    "p_gross = 0.20625\n",
    "p_ret = 0.53\n",
    "p_net = 0.1093125\n",
    "\n",
    "# Define units of analysis for different metrics\n",
    "N = 5000\n",
    "pageview = 40000\n",
    "click = 3200\n",
    "prob_click = 3200 / 40000\n",
    "N_click = N * prob_click\n",
    "prob_enroll = 660 / 40000\n",
    "N_enroll = N * prob_enroll\n",
    "\n",
    "print prob_click\n",
    "print prob_enroll\n",
    "print N_click\n",
    "print N_enroll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The defined standard deviations for the baseline values using sample N:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "se_binom() takes exactly 2 arguments (3 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-df0741c12034>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mse_gross\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mse_binom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_gross\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_click\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mse_retention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mse_binom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_ret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_enroll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mse_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mse_binom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_click\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Print the expected standard deviations for each metric, round to 4th decimal:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: se_binom() takes exactly 2 arguments (3 given)"
     ]
    }
   ],
   "source": [
    "se_gross = se_binom(p_gross, N_click, False)\n",
    "se_retention = se_binom(p_ret, N_enroll, False)\n",
    "se_net = se_binom(p_net, N_click, False)\n",
    "\n",
    "# Print the expected standard deviations for each metric, round to 4th decimal:\n",
    "print '%.4f' % se_gross, '%.4f' % se_retention, '%.4f' % se_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Sizing\n",
    "Sample sizes needed for each evaluation metric using:\n",
    "alpha = 0.05\n",
    "beta = 0.2\n",
    "\n",
    "1. (dmin = 0.01): 25835,\n",
    "2. (dmin = 0.01): 39115,\n",
    "3. (dmin = 0.0075): 27413\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size for Retention: 4741212.12121\n",
      "Size for Gross conv: 645875.0\n",
      "Size for Net conv: 685325.0\n"
     ]
    }
   ],
   "source": [
    "pv_gross = 25835\n",
    "pv_retention = 39115\n",
    "pv_net = 27413\n",
    "\n",
    "# We need to double these to accomodate for both Experiment and Control groups:\n",
    "# For 2, we would need overall pageviews:\n",
    "pv_retention_size = pv_retention/prob_enroll * 2\n",
    "# For the rest:\n",
    "pv_gross_size = pv_gross/prob_click * 2\n",
    "pv_net_size = pv_net/prob_click * 2\n",
    "\n",
    "# Looking at the params, retention will likely be the largest:\n",
    "print 'Size for Retention: ' + str(pv_retention_size)\n",
    "# For the rest:\n",
    "print 'Size for Gross conv: ' + str(pv_gross_size)\n",
    "print 'Size for Net conv: ' + str(pv_net_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duration and exposure\n",
    "\n",
    "Adding a notification is a low-risk procedure, we can direct all or almost all traffic to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days needed to run: 118.53030303\n"
     ]
    }
   ],
   "source": [
    "traffic_ratio = 1.0\n",
    "daily_visits = 40000\n",
    "needed_size = pv_retention_size\n",
    "\n",
    "days_needed = days_needed_to_run(needed_size, daily_visits, traffic_ratio)\n",
    "\n",
    "print 'Days needed to run: ' + str(days_needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That experiment is way too long. This is because gathering enough pageviews to reliably estimate Retention is huge. Therefore this metric should be omitted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days needed to run: 17.133125\n"
     ]
    }
   ],
   "source": [
    "needed_size = max(pv_gross_size, pv_net_size)\n",
    "\n",
    "days_needed = days_needed_to_run(needed_size, daily_visits, traffic_ratio)\n",
    "print 'Days needed to run: ' + str(days_needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks for expected values\n",
    "\n",
    "Confidence intervals are computed for the values that are expected to be observed.\n",
    "\n",
    "We expect the observed values to fall within the confidence interval, else they are expected to not come from same population (eg. have different population parameter(s))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Load data:\n",
    "\n",
    "import csv\n",
    "\n",
    "# Control:\n",
    "with open('data/control.csv', 'rb') as f:\n",
    "    reader = csv.reader(f, delimiter = ';')\n",
    "    # skip headers\n",
    "    reader.next()\n",
    "\n",
    "    # init dict of arrays:\n",
    "    obs = {}\n",
    "    obs['pageviews'] = []\n",
    "    obs['clicks'] = []\n",
    "    obs['enrollments'] = []\n",
    "    obs['payments'] = []\n",
    "    # Add real clicks and pageviews\n",
    "    obs['real_pageviews'] = []\n",
    "    obs['real_clicks'] = []\n",
    "    for row in reader:\n",
    "        obs['pageviews'].append(make_int(row[0]))\n",
    "        obs['clicks'].append(make_int(row[1]))\n",
    "        obs['enrollments'].append(make_int(row[2]))\n",
    "        obs['payments'].append(make_int(row[3]))\n",
    "        # Add real clicks and pageviews since it seems that the\n",
    "        # enrollments and payments stop at some point in the dataset:\n",
    "        if (make_int(row[3]) != 0 and make_int(row[2]) != 0):\n",
    "            obs['real_pageviews'].append(make_int(row[0]))\n",
    "            obs['real_clicks'].append(make_int(row[1]))\n",
    "    # done\n",
    "\n",
    "# Experiment:\n",
    "with open('data/experiment.csv', 'rb') as f:\n",
    "    reader = csv.reader(f, delimiter = ';')\n",
    "    # skip headers\n",
    "    reader.next()\n",
    "\n",
    "    # init dict of arrays:\n",
    "    exp = {}\n",
    "    exp['pageviews'] = []\n",
    "    exp['clicks'] = []\n",
    "    exp['enrollments'] = []\n",
    "    exp['payments'] = []\n",
    "    # Add real clicks and pageviews\n",
    "    exp['real_pageviews'] = []\n",
    "    exp['real_clicks'] = []\n",
    "    for row in reader:\n",
    "        exp['pageviews'].append(make_int(row[0]))\n",
    "        exp['clicks'].append(make_int(row[1]))\n",
    "        exp['enrollments'].append(make_int(row[2]))\n",
    "        exp['payments'].append(make_int(row[3]))\n",
    "        # Add real clicks and pageviews since it seems that the\n",
    "        # enrollments and payments stop at some point in the dataset:\n",
    "        if (make_int(row[3]) != 0 and make_int(row[2]) != 0):\n",
    "            exp['real_pageviews'].append(make_int(row[0]))\n",
    "            exp['real_clicks'].append(make_int(row[1]))\n",
    "    # done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0821258135746\n",
      "CI for pageviews\n",
      "0.0012 0.4988 0.5012\n",
      "CI for clicks\n",
      "0.0041 0.4959 0.5041\n",
      "CI for clickthrough\n",
      "0.0009 0.0812 0.0830\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Confidence intervals for observed values:\n",
    "\n",
    "crit_value = 1.96 # When alpha = 95%\n",
    "\n",
    "# Define expected statistics for sanity checks:\n",
    "\n",
    "# first two define the expected proportion of values falling to control-group\n",
    "p_pageview = 0.5\n",
    "p_click = 0.5\n",
    "# the last is the clickthrough in control\n",
    "p_clickthrough = sum(obs['clicks']) / sum(obs['pageviews'])\n",
    "print p_clickthrough\n",
    "# Define N's for them:\n",
    "N_pageview = sum(obs['pageviews']) + sum(exp['pageviews'])\n",
    "N_click = sum(obs['clicks']) + sum(exp['clicks'])\n",
    "N_clickthrough = sum(obs['pageviews'])\n",
    "\n",
    "# Define SE's for them:\n",
    "se_pageview = se_binom(p_pageview, N_pageview)\n",
    "se_click = se_binom(p_click, N_click)\n",
    "se_clickthrough = se_binom(p_clickthrough, N_clickthrough)\n",
    "\n",
    "# Expected confidence intervals:\n",
    "print 'CI for pageviews'\n",
    "ci_pageviews = ci(crit_value, se_pageview, p_pageview)\n",
    "print '%.4f' % ci_pageviews[0], '%.4f' % ci_pageviews[1], '%.4f' % ci_pageviews[2]\n",
    "print 'CI for clicks'\n",
    "ci_clicks = ci(crit_value, se_click, p_click)\n",
    "print '%.4f' % ci_clicks[0], '%.4f' % ci_clicks[1], '%.4f' % ci_clicks[2]\n",
    "print 'CI for clickthrough'\n",
    "ci_clickthrough = ci(crit_value, se_clickthrough, p_clickthrough)\n",
    "print '%.4f' % ci_clickthrough[0], '%.4f' % ci_clickthrough[1], '%.4f' % ci_clickthrough[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5006\n",
      "0.5005\n",
      "0.0822\n"
     ]
    }
   ],
   "source": [
    "# Now let's define the observed values for the sanity checks:\n",
    "\n",
    "pageview_observed = sum(obs['pageviews']) / (sum(obs['pageviews']) + sum(exp['pageviews']))\n",
    "click_observed = sum(obs['clicks']) / (sum(obs['clicks']) + sum(exp['clicks']))\n",
    "# Here we use that the clickthrough in experiment and check that it falls within the CI's of control values.\n",
    "clickthrough_observed = sum(exp['clicks']) / sum(exp['pageviews'])\n",
    "\n",
    "print '%.4f' % pageview_observed\n",
    "print '%.4f' % click_observed\n",
    "print '%.4f' % clickthrough_observed\n",
    "# All are within the confidence intervals, therefore all pass!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effective size tests\n",
    "\n",
    "Next, let's compute the confidence intervals around the evaluation metrics.\n",
    "\n",
    "These metrics were:\n",
    "Gross conversion: enroll/start_free_trial\n",
    "Net conv: payment/start_free_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17293 17260\n"
     ]
    }
   ],
   "source": [
    "print sum(obs['real_clicks']), sum(exp['real_clicks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0205548745804\n",
      "-0.00487372267454\n",
      "0.208607067404\n",
      "0.115127485312\n",
      "[17293, 17260]\n",
      "[17293, 17260]\n",
      "0.00437167538523\n",
      "0.00343413351293\n",
      "0.00856848375504\n",
      "0.00673090168535\n",
      "Confidence intervals for the change in gross:\n",
      "-0.0291 -0.0120 -0.0206\n",
      "Confidence intervals for the change in net:\n",
      "-0.0116 0.0019 -0.0049\n"
     ]
    }
   ],
   "source": [
    "# Define d hat's, they are the measured difference between control and experiment:\n",
    "d_eval_gross = sum(exp['enrollments']) / sum(exp['real_clicks']) -\\\n",
    "    sum(obs['enrollments']) / sum(obs['real_clicks'])\n",
    "d_eval_net = sum(exp['payments']) / sum(exp['real_clicks']) -\\\n",
    "    sum(obs['payments']) / sum(obs['real_clicks'])\n",
    "\n",
    "print d_eval_gross\n",
    "print d_eval_net\n",
    "# Define p's, they are pooled probabilities of control and experiment:\n",
    "p_eval_gross = (sum(exp['enrollments']) + sum(obs['enrollments'])) /\\\n",
    "    (sum(obs['real_clicks']) + sum(exp['real_clicks']))\n",
    "p_eval_net = (sum(exp['payments']) + sum(obs['payments'])) /\\\n",
    "    (sum(obs['real_clicks']) + sum(exp['real_clicks']))\n",
    "print p_eval_gross\n",
    "print p_eval_net\n",
    "# Define N's, define as array since we calculate a pooled SE:\n",
    "n_eval_gross = [sum(obs['real_clicks']), sum(exp['real_clicks'])]\n",
    "n_eval_net = n_eval_gross\n",
    "\n",
    "print n_eval_gross\n",
    "print n_eval_net\n",
    "# Define SE's\n",
    "se_eval_gross = se_binom(p_eval_gross, n_eval_gross)\n",
    "se_eval_net = se_binom(p_eval_net, n_eval_net)\n",
    "\n",
    "print se_eval_gross\n",
    "print se_eval_net\n",
    "\n",
    "# Define CI's\n",
    "crit_value = 1.96\n",
    "m_eval_gross, ci_eval_gross_lower, ci_eval_gross_upper =\\\n",
    "    ci(crit_value, se_eval_gross, d_eval_gross)\n",
    "m_eval_net, ci_eval_net_lower, ci_eval_net_upper =\\\n",
    "    ci(crit_value, se_eval_net, d_eval_net)\n",
    "\n",
    "print m_eval_gross\n",
    "print m_eval_net\n",
    "\n",
    "print 'Confidence intervals for the change in gross:'\n",
    "print '%.4f' % ci_eval_gross_lower, '%.4f' % ci_eval_gross_upper, '%.4f' % d_eval_gross\n",
    "\n",
    "print 'Confidence intervals for the change in net:'\n",
    "print '%.4f' % ci_eval_net_lower, '%.4f' % ci_eval_net_upper, '%.4f' % d_eval_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gross is statistically significant? Note that gross hypothesis was negative one-way\n",
      "True\n",
      "Net is statistically significant? Note that net hypothesis was two-way\n",
      "False\n",
      "Gross is practically significant?\n",
      "True\n",
      "Net is practically significant?\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Statistical significance:\n",
    "\n",
    "print 'Gross is statistically significant? Note that gross hypothesis was negative one-way'\n",
    "print d_eval_gross < -m_eval_gross\n",
    "\n",
    "print 'Net is statistically significant? Note that net hypothesis was two-way'\n",
    "print d_eval_net > m_eval_net or d_eval_net < -m_eval_net\n",
    "\n",
    "# Practical significance:\n",
    "dmin_gross = 0.01\n",
    "dmin_net = 0.0075\n",
    "\n",
    "print 'Gross is practically significant?'\n",
    "print d_eval_gross < -dmin_gross\n",
    "\n",
    "print 'Net is practically significant?'\n",
    "print d_eval_net > dmin_net or d_eval_net < -dmin_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sign tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of successes for gross: 4\n",
      "Number of successes for net: 10\n",
      "Number of days: 23\n"
     ]
    }
   ],
   "source": [
    "# Let's define the success rate of the experiment day-by-day:\n",
    "successes_gross = []\n",
    "successes_net = []\n",
    "for i in range(len(exp['real_clicks'])):\n",
    "    if (exp['enrollments'][i] / exp['clicks'][i]) >\\\n",
    "        (obs['enrollments'][i] / obs['clicks'][i]):\n",
    "        successes_gross.append(1)\n",
    "    else:\n",
    "        successes_gross.append(0)\n",
    "\n",
    "    if (exp['payments'][i] / exp['clicks'][i]) >\\\n",
    "        (obs['payments'][i] / obs['clicks'][i]):\n",
    "        successes_net.append(1)\n",
    "    else:\n",
    "        successes_net.append(0)\n",
    "# Number of days:\n",
    "num_of_days = len(exp['real_clicks'])\n",
    "\n",
    "print 'Number of successes for gross: ' + str(sum(successes_gross))\n",
    "print 'Number of successes for net: ' + str(sum(successes_net))\n",
    "print 'Number of days: ' + str(num_of_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using an online calculator (source: http://graphpad.com/quickcalcs/binomial1.cfm), the values for the sign test are\n",
    "\n",
    "p_gross = 0.0026 , given two-tailed test. Therefore indicating statistical significance, given alpha of 0.05.\n",
    "\n",
    "p_net = 0.6776  , given two-tailed test. Therefore not indicating statistical significance given alpha of 0.05."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
